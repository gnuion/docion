"use strict";(self.webpackChunkdocion=self.webpackChunkdocion||[]).push([[9408],{7010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"dockerfile-for-production","metadata":{"permalink":"/docion/blog/dockerfile-for-production","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-12-08-write-dockerfile-for-production/index.mdx","source":"@site/blog/2022-12-08-write-dockerfile-for-production/index.mdx","title":"Dockerfile for production","description":"Here we explore how to write a dockerfile for production.","date":"2022-12-08T00:00:00.000Z","formattedDate":"December 8, 2022","tags":[{"label":"docker","permalink":"/docion/blog/tags/docker"}],"readingTime":1.99,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"dockerfile-for-production","title":"Dockerfile for production","authors":["gnuion"],"tags":["docker"]},"nextItem":{"title":"Helm","permalink":"/docion/blog/helm"}},"content":"Here we explore how to write a dockerfile for production.\\n\\n\x3c!-- truncate --\x3e\\n## Writing the Dockerfile\\nWhen creating an image for production, we often don\'t need the artifacts that were created during the build. Therefor, we can use **multitage builds**.\\n\\n```Dockerfile \\n\\n#################\\n# BUILD FOR LOCAL DEVELOPMENT\\n#################\\n\\n# Base image for development\\nFROM node:18-alpine3.15 As development\\n\\n# Update npm\\nRUN npm install -g npm\\n\\n# Create app directory\\nWORKDIR /usr/src/app\\n\\n# Install app dependencies\\nCOPY --chown=node:node package*.json yarn.lock ./\\nRUN yarn install --frozen-lockfile\\n\\n# Bundle app source\\nCOPY --chown=node:node . .\\n\\n# Use the node user from the image (instead of the root user)\\nUSER node\\n\\n\\n#################\\n# BUILD FOR PRODUCTION\\n#################\\n\\n# Base image for building production\\nFROM node:18-alpine3.15 As build\\n# ... your build instructions here\\n\\n# Update npm\\nRUN npm install -g npm\\n\\n# Create app directory\\nWORKDIR /usr/src/app\\n\\n# Install app dependencies\\nCOPY --chown=node:node package*.json yarn.lock ./\\n# In order to run `yarn build` we need access to the Nest CLI which is a dev\\n# dependency. In the previous development stage we ran \\n# `yarn install --frozen-lockfile` which installed all dependencies, so we can \\n# copy over the node_modules directory from the development image\\nCOPY --chown=node:node --from=development /usr/src/app/node_modules ./node_modules\\n\\n# Bundle app source\\nCOPY --chown=node:node . .\\n\\n# Set NODE_ENV environment variable\\nENV NODE_ENV production\\n\\n# Create  a \\"dist\\" folder with the production build\\nRUN yarn build\\n\\n# Running `yarn install --frozen-lockfile` removes the existing node_modules \\n# directory and passing in --only=production ensures that only the production \\n# dependencies are installed. This ensures that the node_modules directory is \\n# as optimized as possible\\nRUN rm -rf node_modules && yarn install --frozen-lockfile --only=production\\n\\n# Use the node user from the image (instead of the root user)\\nUSER node\\n\\n\\n#################\\n# PRODUCTION\\n#################\\n\\n# Base image for production\\nFROM node:18-alpine3.15 As production\\n\\n# Copy the bundled code from the build stage to the production image\\nCOPY --chown=node:node --from=build /usr/src/app/node_modules ./node_modules\\nCOPY --chown=node:node --from=build /usr/src/app/dist ./dist\\n\\n# Use the node user from the image (instead of the root user)\\nUSER node\\n\\n# Start the server using the production build\\nCMD [ \\"node\\", \\"dist/main.js\\" ]\\n```\\n\\n## Building the image\\nTo build the image run:\\n\\n```bash\\ndocker build -t _imageTag_ .\\n```\\n\\nTo test locally, you can run:\\n```bash\\ndocker run --rm -p hostPort:containerPort _imageTag_\\n```\\n\\nNow you can visit `localhost:hostPort` and see your application."},{"id":"helm","metadata":{"permalink":"/docion/blog/helm","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-12-8-helm/index.md","source":"@site/blog/2022-12-8-helm/index.md","title":"Helm","description":"We can define Helm as a package manager for Kubernetes.","date":"2022-12-08T00:00:00.000Z","formattedDate":"December 8, 2022","tags":[{"label":"kubernetes","permalink":"/docion/blog/tags/kubernetes"},{"label":"devops","permalink":"/docion/blog/tags/devops"},{"label":"docker","permalink":"/docion/blog/tags/docker"}],"readingTime":2.345,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"helm","title":"Helm","authors":["gnuion"],"tags":["kubernetes","devops","docker"]},"prevItem":{"title":"Dockerfile for production","permalink":"/docion/blog/dockerfile-for-production"},"nextItem":{"title":"Kubernetes","permalink":"/docion/blog/kubernetes"}},"content":"We can define Helm as a package manager for Kubernetes.\\n\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installation\\nDepending on you operating system, you might follow different instructions for installing helm. For archlinux you can simply run:\\n\\n```bash\\nsudo pacman -S helm\\n```\\n\\n## Concepts\\nThere are three big basic concepts to **Helm**:\\n- Chart - A **Chart** contains all the resource definitions necessary to be run the app in Kubernetes.\\n- Repository - A **Repository** is the place where charts live.\\n- Release - A **Release** is an instance of a chart running in a Kubernetes cluster.\\n\\nWith these concepts in mind, we can now explain Helm like this:\\n\\n> Helm installs **charts** into Kubernetes, creating a new **release** for each installlation. And to find **charts** you can install, you can search the Helm chart **repositories**\\n\\n\\n## Commands \\n### Search chart\\nHelm comes with a powerful search command. It can be used to search two different types of sources:\\n- `helm search hub` searches [the Artifact Hub](https://artifacthub.io/), which lists helm charts from dozens of different repositories.\\n- `helm search repo` searches the repositories that you have added to your local helm client (with `helm repo add).\\n\\nYou can find publicly available charts by runnung `helm search hub`. For example, to find all `wordpress` charts on Artifact Hub run:-\\n\\n```bash\\nhelm search hub wordpress\\n```\\n\\nUsing `helm search repo`, you can find the names of the charts in repositories you have already added:\\n\\n```bash\\n# Add chart to local repository\\nhelm repo add wordpress https://hub.helm.sh/charts/bitnami/wordpress \\n# Search for added chart\\nhelm search repo wordpress\\n```\\n\\n### Install chart\\nTo install a package, use the `helm install` command. It requires at least two arguments:\\n- release name - a name that you pick\\n- chart name - the name of the chart you want to install\\n\\n```bash\\nhelm install releaseName bitnami/wordpress\\n```\\n\\nIf you want Helm to generate a name for you, swap the releaseName with `--generate-name`.\\n\\nTo get information about the state of the release, run:\\n\\n```bash\\nhelm status releaseName\\n```\\n\\n### Configure chart\\nTo see what options are configurable on a chart, use `helm show values`\\n\\n```bash\\nhelm show values bitnami/wordpress\\n```\\n\\nor, if it is a custom added repo:\\n\\n```bash\\nhelm show values nextcloud --repo https://nextcloud.github.io/helm/\\n```\\n\\nAny of t hese settings can be overwritten in a YAML formatted file, and then passed during installation.\\n\\n```bash\\nhelm install chartName --generate-name -f values.yaml\\n```\\n\\n### Uninstall Release\\nTo uninstalled a release from the Kubernetes Cluster run:\\n```bash\\nhelm uninstall releaseName\\n```\\n\\nTo see all deployed releases, run:\\n```\\nhelm list\\n```\\n\\n### Create chart\\nTo get started quickly, run:\\n\\n```bash\\nhelm create chartName\\n```\\n\\nTo package the chartm in a `.tgz` file, run:\\n\\n```bash\\nhelm package chartName\\n```\\n\\nNow you can install the chart using:\\n\\n```\\nhelm install releaseName ./chartName-0.1.0.tgz\\n```"},{"id":"kubernetes","metadata":{"permalink":"/docion/blog/kubernetes","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-12-05-kubernetes/index.mdx","source":"@site/blog/2022-12-05-kubernetes/index.mdx","title":"Kubernetes","description":"This guide assumes a basic understanding of containers. In this blog we explore some basic concepts of kubernetes. It is helpful to have template files.","date":"2022-12-05T00:00:00.000Z","formattedDate":"December 5, 2022","tags":[{"label":"kubernetes","permalink":"/docion/blog/tags/kubernetes"},{"label":"devops","permalink":"/docion/blog/tags/devops"},{"label":"docker","permalink":"/docion/blog/tags/docker"}],"readingTime":9.29,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"kubernetes","title":"Kubernetes","authors":["gnuion"],"tags":["kubernetes","devops","docker"]},"prevItem":{"title":"Helm","permalink":"/docion/blog/helm"},"nextItem":{"title":"Linux Tricks","permalink":"/docion/blog/linux-tricks"}},"content":"This guide assumes a basic understanding of containers. In this blog we explore some basic concepts of kubernetes. It is helpful to have template files.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Nodes\\n\\nNodes host applications in form of containers. Nodes can be **worker nodes** or **master nodes**.\\n\\n### Master Node\\nThe control plane in a master node hosts the **kube-apiserver** which contains:\\n- ETCD - a database that stores information in key-value format\\n- kube-scheduler - deploys containers to worker nodes\\n- controller-manager - monitors and ensures the state of the cluster\\n\\n### Worker Node\\nIn the worker node the **kubelet agent** listens to the **kube-apiserver** and makes sure that the state of the node is as it should by deploying and destroying containers. The **kube-proxy service** runs on worker nodes and ensures container communication.\\n\\n## Core components\\n\\n### ETCD\\n\\nWhen executing a **kubectl command** the **kubeapi-server** authenticates and validates requests. It then transacts with the **ETCD** cluster. You don\'t have to use **kubectl**. You can also directly send **POST requests** to the API. The scheduler monitors the information in **ETCD** and through the **kube-apiserver** it instructs the **kubelet** in the **worker nodes** to create or destroy pods. The **kubelet daemon** reports to the **kube-apiserver** which transacts the information with **ETCD**.\\n\\n\\n### kube-spiserver\\n\\nThe **kube-apiserver** is deployed as a pod within the **kube-system namespace** in the **master node** . To view the pods within the **kube-system** namespace, run:\\n\\n```bash\\nkubectl get pods -n kube-system\\n```\\n\\nYou can see the options within the pod definition file locatet at:\\n\\n```bash\\ncat /etc/kubernetes/manifests/kube-apiserver\\n```\\n\\nYou can view the systemd kube-apiserve service definition by running:\\n\\n```bash\\ncat /etc/systemd/system/kube-apiserver.service\\n```\\n\\nYou can also see the running procces:\\n\\n```bash\\nps -aus | grep kube-apiserver\\n```\\n\\n### kube-controller-manager\\n\\nEnsures the correct state of the kubernetes cluster. It is a process that continiously monitors the state of various components and takes neccesary actions to ensure the correct state. For example, the **node-controller** checks the status of the nodes through the **kube-apiserver** every 5 seconds. If it doesn\'t recieve heartbeats from the node, it marks it unreachable. THe node has then 5 minutes to come back up. If it doesn\'t, it removes the pods from that node and rechedules them on healthy nodes.\\n\\n**kube-controller-manager** is also deployed as a pod within the kube-system namespace:\\n\\n```bash\\nkubectl get pods -n kube-system\\n```\\n\\nYou can view the **kube-controller-manager** options in the manifest folder:\\n\\n```bash\\ncat /etc/kubernetes/manifests/kube-controller-manager.yaml\\n```\\n\\n### kube-scheduler\\n\\nThe **kube-scheduler** only decides which pods go to which node. It doesn\'t actually place the pod on the node. That is the job of the **kubelet** which runs on each node. Depending on pods\' resource requirements the scheduler finds the best nodes for them. It uses a score system to achieve that. Some of the criteria are:\\n- Resource requirements and limits\\n- taints and tolerations\\n- node selectors/affinity\\n\\n\\n### kubelet\\n\\nThe **kubelet** manages the whole **worker node**.\\n\\n### kube-proxy\\n**kube-procy** is a process that runs on each node in the kubernetes cluster. It looks for services and creates the rules for forwarding traefic that targets a service to the corresponding pods. It achieves this by using **ip-tables** rules. It translates the IP of the service to the IP of the matching pod. A **service** is a virtual component, it doesn\'t run any application by itself.\\n\\n## Objects\\n\\n### Pod\\n\\nA **pod** is a single instance of the application. Pods have containers. For scaling you replicate the pods, not the containers within a pod!\\n\\n#### Deploying a pod\\n\\nTo deploy a pod, you can for example run:\\n\\n```bash\\nkubectl run nginx --image nginx\\n```\\n\\nTo see the pod, you can run `kubectl get pods`.\\n\\n#### Pods with yaml\\n\\nKubernetes can use yaml files for creation of objects such as pods, replicas, deployments, services, etc. They all follow a similar structure:\\n\\n```yaml\\n# pod.yaml\\napiVersionL: v1\\nkind: Pod\\nmetadata:\\n  name: podName\\n  labels:\\n    podLabel: podLabelValue\\n    anotherPodLabel: anotherPodLabelValue\\nspec:\\n  containers:\\n    - name: containerName\\n      image: containerImage\\n```\\n\\n##### apiVersion\\n\\nThe **apiVersion** is the version of the kubernetes api you are using to create the object. A few possible values are: \\n\\n| Kind       | Version |\\n| ----       | ------- |\\n| Pod        | v1      |\\n| Service    | v1      |\\n| ReplicaSet | apps/v1 |\\n| Deployment | apps/v1 |\\n\\n##### kind\\n\\nThe **kind** refers to the type of object we want to create. Some possible values are: Pod, Service, ReplicaSet and Deployment.\\n\\n##### metadata\\nThe **metadata** is data about the object like its name and labels.\\n\\n##### spec\\nThe **spec** provides additional information about the object. It is specific to each kind.\\n\\nOnce the definition file is created run the following command to create the pod (assuming you named the definition file `pod.yaml`):\\n\\n```bash\\nkubectl create -f pod.yaml\\n```\\n\\nFor detailed information about the pod, run:\\n\\n```bash\\nkubectl describe pod podName\\n```\\n\\n### ReplicaSet\\n\\nThe **ReplicaSet** helps us run more than one instance of the same **Pod**, thus providing high availability. By using a **ReplicaSet** we can balance the load across multiple pods which can run across worker nodes.\\n\\n#### ReplicaSet with yaml\\n\\n```yaml\\n# ReplicaSet.yaml\\napiVersion: /apps/v1\\nkind: ReplicaSet\\nmetadata:\\n  name: replicaSetName\\n  labels:\\n    replicaSetLabel: replicaSetLabelValue\\nspec:\\n  template:\\n    metadata:\\n      name: podName\\n      labels:\\n        podLabel: podLabelValue\\n        anotherPodLabel: anotherPodLabelValue\\n    spec:\\n      containers:\\n        - name: containerName\\n          image: containerImage\\nreplicas: 2\\nselector:\\n  matchLabels:\\n    podLabel: podLabelValue\\n```\\n\\n##### template\\nThe **template** is the Pod definition without the fields apiVersion and kind.\\n\\n##### replicas\\nThe number of pods that should be running.\\n\\n#### selector\\nThe **selector** identifies the Pods the ReplicaSet should manage. It does so, by matching the labels.\\n\\nWhen ready, run the following command to create the ReplicaSet:\\n\\n```bash\\nkubectl create -f ReplicaSet.yaml\\n```\\n\\nSimilar to the pods, you can run **kubectl** comands to inspect other objects such as the ReplicaSet.\\n\\n```bash\\nkubectl get replicaset\\n```\\n\\n#### Scale ReplicaSet\\n\\nTo scale the **ReplicaSet**, that is to change the target number of running pods, first change the number of **replicas** in the **ReplicaSet definition file**. Then, run the following command:\\n\\n```bash\\nkubectl replace -f ReplicaSet.yaml\\n```\\n\\nAnother way to do it is to use the same definition file, but run **kubectl scale** instead.\\n\\n```bash\\nkubectl scale --replicas=6 -f ReplicaSet.yaml\\n```\\nor\\n\\n```bash\\nkubectl scale --replicas=6 replicaset replicaSetName\\n```\\nThe second method will not modify the file.\\n\\n:::tip\\nDon\'t forget to run `kubectl --help` for helpful information!\\n:::\\n\\n### Deployments\\nA **Deployments** offers extra capabilities to a **ReplicaSet** that allows for seamless version swtiching.\\n\\n#### Deployment definition file.\\nThe **Deployment definition file** is similar to the **Replicaset definition file**.\\n\\n```yaml\\n# ReplicaSet.yaml\\napiVersion: /apps/v1\\nkind: Deployment\\nmetadata:\\n  name: replicaSetName\\n  labels:\\n    replicaSetLabel: replicaSetLabelValue\\nspec:\\n  template:\\n    metadata:\\n      name: podName\\n      labels:\\n        podLabel: podLabelValue\\n        anotherPodLabel: anotherPodLabelValue\\n    spec:\\n      containers:\\n        - name: containerName\\n          image: containerImage\\nreplicas: 2\\nselector:\\n  matchLabels:\\n    podLabel: podLabelValue\\n```\\n\\nSimilar to other objects, **kubectl commands** are also available for **deployments**.\\n\\n### Namespaces\\n**Namescpaces** provide isolation. Cubernetes creates a set of pods and services for its internal purposes under the namespace called **kube-system**. Each namespace can have its own set of policies.Resouce limits can also be assigned to namespaces.\\n\\n#### Connect to services across namespaces\\nWithin a namespace, you can reach a service simply by its name. To target a service from another namespace _dev_ append **.dev.svc.cluster.local** to the service name.\\n\\n#### kubectl with namespaces\\nTo target a specific namespace, append it to the kubectl commmand after **--namespace=** argument. Note, this also works to determine in which namespace an object should be created.\\n\\n#### yaml definition namespace\\nIf you specify a **namespace:** under the **metadata** section in the definition file, by default the object will be created under that namespace.\\n\\n#### How to create a new namespace?\\nLike for any other object, you can use a **namespace definition file**,\\n\\n```yaml\\n## Namespace.yaml\\napiVersionL v1\\nkind: Namespace\\nmetadata:\\n  name: namespaceName\\n```\\n\\nor by running:\\n\\n```bash\\nkubectl create namespace namespaceName\\n```\\n\\n#### Switch namespace\\nTo set a namespace as default for kubectl commands use:\\n\\n```bash\\nkubectl config set-context $(kubectl config current-context) --namespace=namespaceName\\n```\\n\\n### Resource Quota\\nTo define resource limitations within a namespace, use a **Resource Quota**. To create a **Resource Quota**, you can use a definition file.\\n\\n```yaml\\n# ResourceQuota.yaml\\napiVersion: v1\\nkind: ResourceQuota\\nmetadata:\\n  name: resourceQuotaName\\n  namespace: namespaceName\\nspec:\\n  hard:\\n    pods: \\"numberOfPods\\"\\n    requests.cpu: \\"numberOfCpus\\"\\n    requests.memory: \\"valueOfMemory\\"\\n    limits.cpu: \\"numberOfCpus\\"\\n    limit.memory: \\"valueOfMaxMemory\\"\\n```\\n\\n### Services\\n**Services** enable the connection between groups of pods.\\n\\n#### NodePort\\nA **NodePort Service** maps a port on the node to a port on the Pod. The **TargetPort** is the port on the **Pod**. The port on the **Service** itself is refered to as the **Port**. The **Service** has its own IP address within the cluster called **Service ClusterIP**. The **Port** on the **Node** itself is called **NodePort**. The default valid range for **NodePort**s is **30000-32767**\\n\\n#### NodePort Service yaml file\\nTHe definition file for the NodePort Service looks like this:\\n\\n```yaml\\n# NodePortService.yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: serviceName\\nspec:\\n  type: NodePort\\n  ports:\\n    - targetPort: 80\\n      port: 80\\n      nodePort: 30003\\n  selector:\\n    podLabel: podLabelValue\\n```\\n\\nWithin the **ports** array, only the **port** is mandatory. **targetPort** will be assumed to be same as **Port** and **nodePort** will be chosen at random within the valid range. To link the service to a Pod, use labels with selectors.\\n\\n#### ClusterIP\\nA **ClusterIP Service** is a service that is only accesible within a cluster using its ClusterIP or the service name.\\n\\n#### ClusterIP yaml file\\n\\n```yaml\\n# NodePortService.yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: serviceName\\nspec:\\n  type: ClusterIP\\n  ports:\\n    - targetPort: 80\\n      port: 80\\n  selector:\\n    podLabel: podLabelValue\\n```\\n\\n## Scheduling\\nEvery Pod has a filed called **nodeName** that is not set by default. The scheduler schedules a pod on a node by setting the **nodeName** property of the Pod to the name of the node. For scheduling a pod manualy, you can set the **nodeName** yourself.\\n\\n### Binding object.\\nTo reschedule a pod to another node, write a binding definition.\\n\\n```yaml\\napiVersion: v1\\nkind: Binding\\nmetadata:\\n  name: nginx\\ntarget:\\n  apiVersion: 1\\n  kind: Node\\n  name: nodeName\\n```\\n\\nThen, send a post requist to the binding API.\\n\\n```bash\\ncurl --header \\"Context-Type:application/json\\" --request POST --data \'{\\"apiVersion\\":\\"v1\\", \\"kind\\":\\"Binding\\"...\' http://$SERVER/api/v1/namespaces/default/pods/$PODNAME/binding\\n```\\n\\n### Tains\\n### Tolerance\\n### Node Selectors\\n### Node Affinity\\n### DaemonSets\\n\\n## Metrics service\\nCluster performance can be viewed by running\\n```bash\\nkubectl top node\\n```\\n\\nTo log events in a pod use:\\n\\n```bash\\nkubectl logs -f podName\\n```\\n\\n## Networking\\n\\n### Traefik Ingress\\n\\n#### A trafik ingress definition file looks like this:\\n\\n```yaml\\napiVersion: networking.k8s.io/v1\\nkind: Ingress\\nmetadata:\\n  name: IngressName\\n  namespace: default\\n\\nspec:\\n  rules:\\n    - host: example.com\\n      http:\\n        paths:\\n          - path: /\\n            pathType: Exact\\n            backend:\\n              service:\\n                name:  serviceName\\n                port:\\n                  number: 80\\n```\\n\\n## Storage\\n\\n### Local Storage Provider.\\nA Local Storage Provider enabled the ability to create persistent volume claims using local storage on the node.\\n\\n#### Persistent Volume Claim \\n```yaml\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: persistentVolumeClaimName\\n  namespace: default\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  storageClassName: local-path\\n  resources:\\n    requests:\\n      storage: 2Gi\\n```\\n\\n#### Pod with local storage\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: podName\\n  namespace: default\\nspec:\\n  containers:\\n    - image:imageName\\n      name: containerName\\n      imagePullPolicy: IfNotPresent\\n      volumeMounts:\\n        - name: volumeName \\n          mountPath: pathOnTheContainer\\n      ports:\\n        - containerPort: portNumber\\n  volumes:\\n    - name: volumeName\\n      persistentVolumeClaim:\\n        claimName: persistentVolumeClaimName\\n```\\n\\nThen, you can apply the yaml using kubectl."},{"id":"linux-tricks","metadata":{"permalink":"/docion/blog/linux-tricks","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-11-28-linux-tricks/index.mdx","source":"@site/blog/2022-11-28-linux-tricks/index.mdx","title":"Linux Tricks","description":"Here we document some handy linux tips and tricks.","date":"2022-11-28T00:00:00.000Z","formattedDate":"November 28, 2022","tags":[{"label":"linux","permalink":"/docion/blog/tags/linux"},{"label":"devops","permalink":"/docion/blog/tags/devops"}],"readingTime":0.305,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"linux-tricks","title":"Linux Tricks","authors":["gnuion"],"tags":["linux","devops"]},"prevItem":{"title":"Kubernetes","permalink":"/docion/blog/kubernetes"},"nextItem":{"title":"Install custom image on Contabo","permalink":"/docion/blog/install-custom-image-on-contabo"}},"content":"Here we document some handy linux tips and tricks.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Command aliases\\n\\nCreate `.bash_aliases` in your home directory.\\n\\n```bash\\ntouch ~/.bash_aliases\\n```\\n\\nWrite the following inside `.bash_aliases`:\\n\\n```bash\\n# ~/.bash_aliases\\nalias l=\'ls -lah\'\\n```\\n\\nNow source `.bash_aliases` from inside `.bashrc`.\\n\\n```bash\\n# ~/.bashrc\\n...\\nsource ~/.bash_aliases\\n```\\n\\nRestart terminal. Now you can use `l` instead of `ls -lah`."},{"id":"install-custom-image-on-contabo","metadata":{"permalink":"/docion/blog/install-custom-image-on-contabo","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-11-26-install-custom-image-on-contabo/index.md","source":"@site/blog/2022-11-26-install-custom-image-on-contabo/index.md","title":"Install custom image on Contabo","description":"How to install a custom Arch Image on Contabo.","date":"2022-11-26T00:00:00.000Z","formattedDate":"November 26, 2022","tags":[{"label":"backend","permalink":"/docion/blog/tags/backend"}],"readingTime":2.255,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"install-custom-image-on-contabo","title":"Install custom image on Contabo","authors":["gnuion"],"tags":["backend"]},"prevItem":{"title":"Linux Tricks","permalink":"/docion/blog/linux-tricks"},"nextItem":{"title":"Redux Toolkit Template","permalink":"/docion/blog/redux-toolkit-template"}},"content":"How to install a custom Arch Image on Contabo.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Choose Custom installation\\n\\nDisable cloud-init\\n\\n![Custom Install](./disable_could_init.png)\\n\\nChoose custom install\\n\\n![Custom Install](./initiate_custom_install.png)\\n\\nNow use a VNC client with the provided credentials from contabo. Then choose your image. Here I chose Arch Linux.\\n\\n![Custom Install](./archlinux_installation_screen.png)\\n\\nDo a ping test:\\n\\n```bash\\nping google.com\\n```\\n\\n### Create Partitions\\n\\nCreate an empty GPT partition table. Use `m` for a list of avalable commands.\\n\\n```bash\\nfdisk /dev/sda\\n```\\n\\nCreate a `bios_grub` partiton of 1MiB starting at 1MiB from the start of the disk.\\n\\n```bash\\nn\\n2048\\n+1MiB\\n```\\n\\nSet type as `bios_grub`.\\n\\n```bash\\nt\\n4\\n```\\n\\nNow create the `root` partition with the size of 30GiB:\\n\\n```bash\\nn\\n2\\n4096\\n+30GiB\\n```\\n\\nCreate other partitions you might need, for example `home`.\\n\\nFormat partitions with a ext4 filesystem:\\n\\n```bash\\nmkfs -t ext4 /dev/sda2\\n```\\n\\nMount root partition in `/mnt` directory. In case you craeted a `home` partition, mount it to `/mnt/home`\\n\\n```bash\\nmount /dev/sda2 /mnt\\nmount -o x-mount.mkdir /dev/sda4 /mnt/home\\n```\\n\\nInstall base system:\\n\\n```bash\\npacstrap -i /mnt base linux linux-firmware\\n```\\n\\nConfigure fstab for the new installation.\\n\\n```bash\\ngenfstab -U /mnt >> /mnt/etc/fstab\\n```\\n\\n### Chroot\\n\\nChange root into the new system. Then install a text editor.\\n\\n```bash\\narch-chroot /mnt\\npacman -S nano\\n```\\n\\nSet timezone:\\n\\n```bash\\nln -sf /usr/share/zoneinfo/Region/City /etc/localtime\\n```\\n\\nEdit `/etc/locale.gen` by uncommenting `en_US.UTF-8 UTF-8`. Generate the locales.\\n\\n```bash\\nnano /etc/locale.gen\\nlocale-gen\\n```\\n\\nCreate a locale.conf file, and set the LANG variable accordingly.\\n\\n```conf\\n# /etc/locale.conf\\nLANG=en_US.UTF-8\\n```\\n\\nImportant! Don\'t forget to setup a root password!\\n\\n```bash\\npasswd\\n```\\n\\nInstall bootloader.\\n\\n```bash\\npacman -S grub\\ngrub-install /dev/sda --target=i386-pc\\ngrub-mkconfig -o /boot/grub/grub.cfg\\n```\\n\\nReboot and good luck \ud83e\udd1e.\\n\\n### Configuring network\\n\\nTo use systemd-networkd, enable the service. When reconiguring, restart service.\\n\\n```bash\\nsystemctl enable --now systemd-networkd\\n```\\n\\nCheck network device name using `ip a`.\\n\\n#### Wired adapter using DHCP\\n\\n```bash\\n# /etc/systemd/network/20-wired.network\\n[Match]\\nName=YOUR_NETWORK_DEVICE_NAME\\n\\n[Network]\\nDHCP=yes\\nDNS=8.8.8.8\\n```\\n\\n#### Wired adapter using a static IP\\n\\n```bash\\n# /etc/systemd/network/20-wired.network\\n[Match]\\nName=YOUR_NETWORK_DEVICE_NAME\\n\\n[Network]\\nAddress=YOUR_STATIC_IP_ADDRESS\\nGateway=YOUR_GATEWAY\\nDNS=8.8.8.8\\n```\\n\\n```bash\\nsystemctl enable --now systemd-networkd\\n```\\n\\n### Install sudo\\n\\n```bash\\npacman -S sudo\\n```\\n\\nCreate a new user.\\n\\n```bash\\nuseradd --create-home YOUR_USERNAME\\nusermod --append --groups wheel\\n```\\n\\nEdit sudoes file to uncommen wheel user.\\n\\n```bash\\nEDITOR=nano visudo\\n\\n# Then find and uncomment\\n%wheel ALL=(ALL:ALL) NOPASSWD:ALL\\n\\n# Then login to user and test\\nsu YOUR_USERNAME\\nsudo echo hello\\n```\\n\\n### Enable SSH\\n\\n```bash\\nsudo pacman -S openssh\\nsudo systemctl enable --now sshd\\n```\\n\\nGenerate __SSH__ keys on client and server.\\n\\n```bash\\nssh-keygen -t ed25519\\n```\\n\\nCopy the content of the public key of the client and paste it to the file `~/.ssh/authorized_keys` on the server.\\n\\nForce public key authentication\\n\\n```bash\\n# /etc/ssh/sshd_config\\nPasswordAuthentication no\\nAuthenticationMethods publickey\\n```"},{"id":"redux-toolkit-template","metadata":{"permalink":"/docion/blog/redux-toolkit-template","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-11-15-redux-toolkit-template/index.mdx","source":"@site/blog/2022-11-15-redux-toolkit-template/index.mdx","title":"Redux Toolkit Template","description":"Redux toolkit (RTK) offers a great solution for state management and caching data. Let\'s get started!","date":"2022-11-15T00:00:00.000Z","formattedDate":"November 15, 2022","tags":[{"label":"react","permalink":"/docion/blog/tags/react"},{"label":"redux toolkit","permalink":"/docion/blog/tags/redux-toolkit"},{"label":"frontend","permalink":"/docion/blog/tags/frontend"}],"readingTime":2.655,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"redux-toolkit-template","title":"Redux Toolkit Template","authors":["gnuion"],"tags":["react","redux toolkit","frontend"]},"prevItem":{"title":"Install custom image on Contabo","permalink":"/docion/blog/install-custom-image-on-contabo"},"nextItem":{"title":"Vite Import Alias","permalink":"/docion/blog/vite-import-alias"}},"content":"Redux toolkit (RTK) offers a great solution for state management and caching data. Let\'s get started!\\n\\n\x3c!-- truncate --\x3e\\n\\n## Create a new project\\nFollow the prompts. Use react and typescript.\\n```bash\\nyarn create vite\\n```\\n\\nInstall dependencies:\\n```bash\\nyarn i @reduxjs/toolkit react-redux axios\\n```\\n\\n## Create redux slice\\n\\nCreate a folder named `counter`\\n\\n```bash\\nmkdir ./src/features/counter\\n```\\n\\nInside the `counter` folder, create a file named `counterSlice.ts`. It should have the following content.\\n\\n```typescript\\n// counterSlice.ts\\n\\nimport { createSlice, PayloadAction } from \'@reduxjs/toolkit\'\\n\\ninterface CounterState {\\n  value: number\\n}\\n\\nconst initialState: CounterState = {\\n  value: 0\\n}\\n\\nconst counterSlice = createSlice({\\n  name: \'counter\',\\n  initialState,\\n  reducers: {\\n    incremented(state) {\\n      state.value++;\\n    },\\n      amountAdded(state, action: PayloadAction<number>) {\\n      state.value += action.payload\\n    }\\n  }\\n});\\n\\n\\nexport const { incremented, amountAdded } = counterSlice.actions\\nexport default counterSlice.reducer\\n```\\n\\n## Configure redux store\\n\\nMake a new folder called `app`\\n\\n```bash\\nmkdir ./src/app\\n```\\n\\nInside the `app` folder, create a file named `store.ts`. It should have the following content:\\n\\n```typescript\\nimport { configureStore } from \\"@reduxjs/toolkit\\";\\nimport counterReducer from \'../features/counter/counterSlice\'\\n\\nexport const store = configureStore({\\n  reducer: {\\n    counter: counterReducer\\n  }\\n})\\n\\nexport type AppDispatch = typeof store.dispatch;\\nexport type RootState = ReturnType<typeof store.getState>;\\n```\\n\\nSetup the redux react provider so the application can access the store. Inside the `main.ts` file, make adjustments:\\n\\n```typescript\\nimport { Provider } from \'react-redux\'\\nimport { store } from \'./app/store\'\\n...\\n  <Provider store={store}>\\n    <App />\\n  </Provider>\\n...\\n```\\n\\nInside the `./src/app` folder, let\'s make a file called `hooks.ts`. It should have the following content:\\n\\n```typescript\\nimport { TypedUseSelectorHook, useDispatch, useSelector } from \'react-redux\'\\nimport { RootState, AppDispatch } from \'./store\'\\n\\nexport const useAppDispatch = () => useDispatch<AppDispatch>()\\nexport const useAppSelector: TypedUseSelectorHook<RootState> = useSelector;\\n```\\n\\n## Using the store\\n\\nInside `App.ts`, import those hooks and the `incremented` action creator:\\n\\n```typescript\\nimport { useAppDispatch, useAppSelector } from \'./app/hooks\'\\nimport { incremented } from \'./features/counter/counterSlice\'\\n```\\n\\nNow read the count value using:\\n\\n```typescript\\nconst count = useAppSelector((state) => state.counter.value)\\n```\\n\\nDispatch action using: \\n```typescript\\nconst dispatch = useAppDispatch()\\n...\\n  // onClick={() => dispatch(incremented())}\\n  onClick={() => dispatch(amountAdded(5))}\\n...\\n```\\n\\n## Using RTK Query\\n\\nInside the `./src/feature/dogs/` folder, create a file named `dogsApiSlice.ts`. It should have the following content:\\n\\n```typescript\\nimport { createApi, fetchBaseQuery } from \'@reduxjs/toolkit/query/react\'\\n\\nconst DOGS_API_KEY = \'your_dog_api_key_here\'\\n\\ninterface Breed {\\n  id: string;\\n  name: string;\\n  image: {\\n    url: string;\\n  }\\n}\\n\\nexport const dogsApiSlice = createApi({\\n  reducerPath: \'api\',\\n  baseQuery: fetchBaseQuery({\\n    baseUrl: \'https://api.thedogapi.com/v1\',\\n    prepareHeaders(headers) {\\n      headers.set(\'x-api-key\', DOGS_API_KEY);\\n      return headers\\n    }\\n  }),\\n  endpoints(builder) {\\n    return {\\n      fetchBreeds: builder.query<Breed[], number | void>({\\n        query(limit = 10) {\\n          return `/breeds?limit=${limit}`\\n        }\\n      })\\n    }\\n  }\\n})\\n\\nexport const { useFetchBreedsQuery } = dogsApiSlice\\n```\\n\\nLet\'s go back to our `store.ts` file. After importing, adding the reducer and the middleware, it should look like this:\\n\\n```typescript\\nimport { configureStore } from \\"@reduxjs/toolkit\\";\\nimport counterReducer from \'../features/counter/counterSlice\'\\nimport { dogsApiSlice } from \\"../features/dogs/dogsApiSlice\\";\\n\\nexport const store = configureStore({\\n  reducer: {\\n    counter: counterReducer,\\n    [dogsApiSlice.reducerPath]: dogsApiSlice.reducer\\n  },\\n  middleware: (getDefaultMiddleware) => {\\n    return getDefaultMiddleware().concat(dogsApiSlice.middleware)\\n  }\\n})\\n\\nexport type AppDispatch = typeof store.dispatch;\\nexport type RootState = ReturnType<typeof store.getState>;\\n```\\n\\nNow, to fetch, go to `App.ts`.\\n\\n```typescript\\nimport { useFetchBreedsQuery } from \'./features/dogs/dogsApiSlice\'\\n\\nfunction App() {\\n  const { data = [], isFetching } = useFetchBreedsQuery();\\n  ...\\n}\\n```"},{"id":"vite-import-alias","metadata":{"permalink":"/docion/blog/vite-import-alias","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-11-9-vite-alias/index.mdx","source":"@site/blog/2022-11-9-vite-alias/index.mdx","title":"Vite Import Alias","description":"Under vite.config.ts, inside the defineConfig object, add:","date":"2022-11-09T00:00:00.000Z","formattedDate":"November 9, 2022","tags":[{"label":"vite","permalink":"/docion/blog/tags/vite"},{"label":"frontend","permalink":"/docion/blog/tags/frontend"}],"readingTime":0.24,"hasTruncateMarker":false,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"vite-import-alias","title":"Vite Import Alias","authors":["gnuion"],"tags":["vite","frontend"]},"prevItem":{"title":"Redux Toolkit Template","permalink":"/docion/blog/redux-toolkit-template"},"nextItem":{"title":"Kubernetes Nginx Ingress","permalink":"/docion/blog/k8s-nginx-ingress"}},"content":"Under `vite.config.ts`, inside the `defineConfig` object, add:\\n\\n```typescript\\ndefineConfig: {\\n  resolve: {\\n    alias: {\\n      \'@\': path.resolve(__dirname, \'./src\')\\n    }\\n  }\\n}\\n```\\n\\nThen, under `tsconfig.json`, inside the `compilerOptions` object, add:\\n\\n```json\\n\\"compilerOptions\\": {\\n  \\"paths\\": {\\n    \\"@/*\\": [\\"./src/*\\"]\\n  }\\n}\\n```\\n\\nNow, instead of `../../../component`, you can simply use `@/component`."},{"id":"k8s-nginx-ingress","metadata":{"permalink":"/docion/blog/k8s-nginx-ingress","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-31-k8s-nginx-ingress/index.mdx","source":"@site/blog/2022-10-31-k8s-nginx-ingress/index.mdx","title":"Kubernetes Nginx Ingress","description":"After bootstrapping Kubernetes using kubeadm and learning some Kubernetes primitives, we start to learn about an ingress controller. For convenience, we will use Helm as our package manager for Kubernetes.","date":"2022-10-31T00:00:00.000Z","formattedDate":"October 31, 2022","tags":[{"label":"kubernetes","permalink":"/docion/blog/tags/kubernetes"}],"readingTime":1.325,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"k8s-nginx-ingress","title":"Kubernetes Nginx Ingress","authors":["gnuion"],"tags":["kubernetes"]},"prevItem":{"title":"Vite Import Alias","permalink":"/docion/blog/vite-import-alias"},"nextItem":{"title":"Minikube","permalink":"/docion/blog/minikube"}},"content":"After bootstrapping Kubernetes using [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/) and learning some Kubernetes primitives, we start to learn about an ingress controller. For convenience, we will use Helm as our package manager for Kubernetes.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installing a container runner\\n\\nLet\'s make sure we have a container runner installed and the service running. For Arch Linux:\\n\\nInstall CRI-O:\\n\\n```\\nsudo pacman -Syu cri-o\\n```\\n\\nEnable the CRI-O service:\\n```\\nsudo systemctl enable --now crio\\n```\\n\\n## Bootstrapping Kubernetes using kubeadm\\n\\nNow we can bootstrap our Kubernetes installation by running:\\n\\n```\\nsudo kubeadm init --pod-network-cidr=192.168.0.0/16\\n```\\n\\nTo be able to run kubectl from current user use:\\n\\n```\\nmkdir -p $HOME/.kube\\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\\n```\\n\\nNow install [Calico](https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart):\\n\\n1. Install the Tigera Calico operator and custom resource definitions.\\n\\n```\\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.3/manifests/tigera-operator.yaml\\n```\\n\\n2. Install Calico by creating the necessary custom resource:\\n\\n```\\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.3/manifests/custom-resources.yaml\\n```\\n\\nVerify that all system pods are running:\\n```\\nkubectl get pods --all-namespaces\\n```\\n\\nBy default, new pods will not be scheduled on the control plane node. You can change that by running:\\n\\n```\\nkubectl taint nodes --all node-role.kubernetes.io/control-plane-\\n```\\n\\n## Using Helm\\n\\nTo install helm use:\\n\\n```\\nsudo pacman -S helm\\n```\\n\\nTo allow referencing to localhost via ipv6, modify `/etc/systemd/resolved.conf` to include:\\n\\n```\\n# /etc/systemd/resolved.conf\\nDNSStubListenerExtra=[::1]:53\\n```\\n\\nAdd nginx repo by running:\\n\\n```\\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx=\\n```\\n\\nNow update helm repo:\\n\\n```\\nhelm repo update\\n```\\n\\nTo view chart configuration values run:\\n\\n```\\nhelm show values ingress-nginx/ingress-nginx\\n```\\n\\nTo install the chart run:\\n\\n```\\nhelm install ingress-nginx ingress-nginx/ingress-nginx\\n```"},{"id":"minikube","metadata":{"permalink":"/docion/blog/minikube","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-28-minikube/index.mdx","source":"@site/blog/2022-10-28-minikube/index.mdx","title":"Minikube","description":"Kubernetes is a enterprise application and is designed to run across multiple machines. Each machine is called a node.","date":"2022-10-28T00:00:00.000Z","formattedDate":"October 28, 2022","tags":[{"label":"angular","permalink":"/docion/blog/tags/angular"}],"readingTime":0.8,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"minikube","title":"Minikube","authors":["gnuion"],"tags":["angular"]},"prevItem":{"title":"Kubernetes Nginx Ingress","permalink":"/docion/blog/k8s-nginx-ingress"},"nextItem":{"title":"Angular in Docker","permalink":"/docion/blog/angular-in-docker"}},"content":"Kubernetes is a enterprise application and is designed to run across multiple machines. Each machine is called a node. \\n\\n\x3c!-- truncate --\x3e\\n\\n## Setting up a learning environment\\n\\nWhen learning, we might have only one machine available. In that case we can create a single node setup using [minikube](https://minikube.sigs.k8s.io/docs/start/). Here we assume we already know basics of docker. Continue buy installing minikube following the documentation for your specific OS. In ArchLinux type:\\n\\n```\\nsudo pacman -Sy minikube\\n```\\n\\nTo start a single node cluster run:\\n\\n```\\nminikube start\\n```\\n\\nSelect docker as the execution engine. VMs are also an option, but consume more resources. You can check the newly created cluster using:\\n\\n``` \\nminikube status\\n```\\n\\nTo stop the cluster run:\\n\\n```\\nminikube stop\\n```\\n\\nVisit the [documentation](https://minikube.sigs.k8s.io/docs/start/) for more minikube commands.\\n\\n## Interact with your cluster\\n\\nIf you already have kubectl installed, you can now use it to access your shiny new cluster:\\n\\n```\\nkubectl get po -A\\n```"},{"id":"angular-in-docker","metadata":{"permalink":"/docion/blog/angular-in-docker","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-25-angular-in-docker/index.mdx","source":"@site/blog/2022-10-25-angular-in-docker/index.mdx","title":"Angular in Docker","description":"Angular not always supports the latest node.js version. Docker can help keep our system clean.","date":"2022-10-25T00:00:00.000Z","formattedDate":"October 25, 2022","tags":[{"label":"angular","permalink":"/docion/blog/tags/angular"}],"readingTime":0.81,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"angular-in-docker","title":"Angular in Docker","authors":["gnuion"],"tags":["angular"]},"prevItem":{"title":"Minikube","permalink":"/docion/blog/minikube"},"nextItem":{"title":"Make RAID0 array using MDADM","permalink":"/docion/blog/raid0-with-mdadm"}},"content":"Angular not always supports the latest node.js version. Docker can help keep our system clean.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Create node user\\n\\nFor best practice, create node user and append node group to current user.\\n\\n```\\nsudo useradd node\\nsudo usermod --append --groups node $USER\\n```\\n\\n## Build Angular image:\\n\\nUse the node version Angular supports. At the time of this writing it is version 14.\\n\\n```Dockerfile\\nFROM node:14-alpine\\nRUN npm install -g @angular/cli\\nUSER node\\nWORKDIR /app\\nEXPOSE 4200 49153\\nCMD npm start\\n```\\n\\nBuild the image. In this example it is tagged `ng`:\\n\\n```\\ndocker build --tag ng .\\n```\\n\\n## Using the Angular CLI within Docker\\n\\nRun the development container:\\n\\n```\\ndocker run -it -v $(pwd):/app -p 4200:4200 -p 49153:49153 --name ng ng sh\\n```\\n\\nCreate a new project:\\n\\n```\\nng new --skip-git\\n```\\n\\nAdjust `start` script in package.json to:\\n\\n```\\n start\\": \\"ng serve --host 0.0.0.0 --poll\\"\\n```\\n\\nOtherwise the port would not be accessible from outside the container."},{"id":"raid0-with-mdadm","metadata":{"permalink":"/docion/blog/raid0-with-mdadm","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-15-raid0-with-mdadm/index.mdx","source":"@site/blog/2022-10-15-raid0-with-mdadm/index.mdx","title":"Make RAID0 array using MDADM","description":"Sometimes you need RAID0 for increased capacity and speed.","date":"2022-10-15T00:00:00.000Z","formattedDate":"October 15, 2022","tags":[{"label":"web3","permalink":"/docion/blog/tags/web-3"}],"readingTime":0.76,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"raid0-with-mdadm","title":"Make RAID0 array using MDADM","authors":["gnuion"],"tags":["web3"]},"prevItem":{"title":"Angular in Docker","permalink":"/docion/blog/angular-in-docker"},"nextItem":{"title":"Build Chia Docker Container","permalink":"/docion/blog/build-chia-docker-container"}},"content":"Sometimes you need RAID0 for increased capacity and speed.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Load needed modules\\n\\nStart with loading the raid0 kernel module:\\n\\n```\\nmodprobe raid0\\n```\\n\\nAdd it to /etc/modules-load.d so it gets loaded during next reboot:\\n\\n```\\necho raid0 >> /etc/modules-load.d/raid0.conf\\n```\\n\\n## Assemble existing array\\n\\nFind UUID of target array:\\n\\n```\\nblkid\\n```\\n\\nAssemble using mdadm:\\n\\n```\\nmdadm --assemble /dev/md0 --uuid <array_uuid>\\n```\\n\\n## Make persistant on Alpine:\\n\\nCreate the /etc/mdadm.conf file so mdadm knows how your RAID is set up:\\n\\n```\\nmdadm --detail --scan > /etc/mdadm.conf\\n```\\n\\nTo make sure the raid devices start during the next reboot run:\\n\\n```\\nrc-update add mdadm-raid\\n```\\n\\nTo use the raid array in /etc/fstab at boot, the mdadm service must be started at boot time:\\n\\n```\\nrc-update add mdadm boot\\n```\\n\\n```\\nrc-update add mdadm-raid boot\\n```\\n\\nFinally, to persist changes in `/etc` directory, run (Alpine only!):\\n\\n```\\nlbu ci\\n```"},{"id":"build-chia-docker-container","metadata":{"permalink":"/docion/blog/build-chia-docker-container","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-13-build-chia-docker-container/index.mdx","source":"@site/blog/2022-10-13-build-chia-docker-container/index.mdx","title":"Build Chia Docker Container","description":"Chia Blockchain is a protocol that uses Proof-Of-Space-Time (PoST) for consensus. Here we will use an image container for quick configuration.","date":"2022-10-13T00:00:00.000Z","formattedDate":"October 13, 2022","tags":[{"label":"web3","permalink":"/docion/blog/tags/web-3"}],"readingTime":0.45,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"build-chia-docker-container","title":"Build Chia Docker Container","authors":["gnuion"],"tags":["web3"]},"prevItem":{"title":"Make RAID0 array using MDADM","permalink":"/docion/blog/raid0-with-mdadm"},"nextItem":{"title":"Virtualization with QEMU","permalink":"/docion/blog/virtualization-with-qemu"}},"content":"Chia Blockchain is a protocol that uses Proof-Of-Space-Time (PoST) for consensus. Here we will use an image container for quick configuration.\\n\\n\x3c!-- truncate --\x3e\\n\\n[Docker](https://docs.docker.com/get-started/overview/) enables you to seperate your applicatin from your infrastructure so you can deliver software quickly.\\n\\n## Run chia docker\\n\\n- Clone repe:\\n\\n```bash\\ngit clone https://github.com/gnuion/chia-docker.git\\n```\\n\\n- Configure and run `docker-compose up`. You can use my image, or build it yourself.\\n\\nYou can then start and stop your services using `docker-compose up` and `docker-compose down` respectively.\\n\\n## Build it yourself\\n\\nVisit [Chia in Docker](https://github.com/gnuion/chia-docker/)"},{"id":"virtualization-with-qemu","metadata":{"permalink":"/docion/blog/virtualization-with-qemu","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-12-virtualization-with-qemu/index.mdx","source":"@site/blog/2022-10-12-virtualization-with-qemu/index.mdx","title":"Virtualization with QEMU","description":"A virtual machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system.","date":"2022-10-12T00:00:00.000Z","formattedDate":"October 12, 2022","tags":[{"label":"web","permalink":"/docion/blog/tags/web"}],"readingTime":0.275,"hasTruncateMarker":false,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"virtualization-with-qemu","title":"Virtualization with QEMU","authors":["gnuion"],"tags":["web"]},"prevItem":{"title":"Build Chia Docker Container","permalink":"/docion/blog/build-chia-docker-container"},"nextItem":{"title":"Scaffolding React App","permalink":"/docion/blog/scaffolding-react-app"}},"content":"A virtual machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system.\\n\\nOne easy way to get started in [ArchLinux](https://wiki.archlinux.org/title/Virt-Manager) is with VirtManager. The GUI is straighforward.\\n\\n```\\npacman -S virt-manager qemu-desktop libvirt edk2-ovmf dnsmasq iptables-nft\\n```"},{"id":"scaffolding-react-app","metadata":{"permalink":"/docion/blog/scaffolding-react-app","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2022-10-10-react-app-scaffold/index.mdx","source":"@site/blog/2022-10-10-react-app-scaffold/index.mdx","title":"Scaffolding React App","description":"React is a library it doesn\'t care about project structure. You have to manage it instead.","date":"2022-10-10T00:00:00.000Z","formattedDate":"October 10, 2022","tags":[{"label":"web","permalink":"/docion/blog/tags/web"}],"readingTime":0.385,"hasTruncateMarker":true,"authors":[{"name":"Jon Zuka","title":"Blog owner","url":"https://github.com/gnuion","imageURL":"https://github.com/gnuion.png","key":"gnuion"}],"frontMatter":{"slug":"scaffolding-react-app","title":"Scaffolding React App","authors":["gnuion"],"tags":["web"]},"prevItem":{"title":"Virtualization with QEMU","permalink":"/docion/blog/virtualization-with-qemu"},"nextItem":{"title":"Welcome","permalink":"/docion/blog/welcome"}},"content":"React is a library it doesn\'t care about project structure. You have to manage it instead.\\n\\n\x3c!-- truncate --\x3e\\n\\nScaffolding using [vite](https://vitejs.dev/guide/):\\n\\n```bash\\npnpm create vite\\n```\\n\\nThen follow the prompts!\\n\\n:::tip\\nCheck out Awesome Vite for [community maintained templates](https://github.com/vitejs/awesome-vite#templates) that include other tools or target different frameworks. You can use a tool like [degit](https://github.com/Rich-Harris/degit) to scaffold your project with the [Vitamin](https://github.com/wtchnm/Vitamin) template.\\n\\n```\\nnpx degit wtchnm/Vitamin#main my-app\\ncd my-project\\n\\npnpm install\\npnpm run dev\\n```\\n\\n:::"},{"id":"welcome","metadata":{"permalink":"/docion/blog/welcome","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","formattedDate":"August 26, 2021","tags":[{"label":"facebook","permalink":"/docion/blog/tags/facebook"},{"label":"hello","permalink":"/docion/blog/tags/hello"},{"label":"docusaurus","permalink":"/docion/blog/tags/docusaurus"}],"readingTime":0.405,"hasTruncateMarker":false,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Front End Engineer @ Facebook","url":"https://github.com/yangshun","imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"prevItem":{"title":"Scaffolding React App","permalink":"/docion/blog/scaffolding-react-app"},"nextItem":{"title":"MDX Blog Post","permalink":"/docion/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\n\\nSimply add Markdown files (or folders) to the `blog` directory.\\n\\nRegular blog authors can be added to `authors.yml`.\\n\\nThe blog post date can be extracted from filenames, such as:\\n\\n- `2019-05-30-welcome.md`\\n- `2019-05-30-welcome/index.md`\\n\\nA blog post folder can be convenient to co-locate blog post images:\\n\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\\n\\nThe blog supports tags as well!\\n\\n**And if you don\'t want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/docion/blog/mdx-blog-post","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2021-08-01-mdx-blog-post.mdx","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","formattedDate":"August 1, 2021","tags":[{"label":"docusaurus","permalink":"/docion/blog/tags/docusaurus"}],"readingTime":0.175,"hasTruncateMarker":false,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"prevItem":{"title":"Welcome","permalink":"/docion/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/docion/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\\n\\n:::tip\\n\\nUse the power of React to create interactive blog posts.\\n\\n```js\\n<button onClick={() => alert(\'button clicked!\')}>Click me!</button>\\n```\\n\\n<button onClick={() => alert(\'button clicked!\')}>Click me!</button>\\n\\n:::"},{"id":"long-blog-post","metadata":{"permalink":"/docion/blog/long-blog-post","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2019-05-29-long-blog-post.mdx","source":"@site/blog/2019-05-29-long-blog-post.mdx","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","formattedDate":"May 29, 2019","tags":[{"label":"hello","permalink":"/docion/blog/tags/hello"},{"label":"docusaurus","permalink":"/docion/blog/tags/docusaurus"}],"readingTime":2.06,"hasTruncateMarker":true,"authors":[{"name":"Endilie Yacop Sucipto","title":"Maintainer of Docusaurus","url":"https://github.com/endiliey","imageURL":"https://github.com/endiliey.png","key":"endi"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"endi","tags":["hello","docusaurus"]},"prevItem":{"title":"MDX Blog Post","permalink":"/docion/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/docion/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\\n\\nUse a `\x3c!--` `truncate` `--\x3e` comment to limit blog post size in the list view.\\n\\n\x3c!-- truncate --\x3e\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/docion/blog/first-blog-post","editUrl":"https://github.com/gnuion/docion/tree/gh-edits/blog/2019-05-28-first-blog-post.md","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","date":"2019-05-28T00:00:00.000Z","formattedDate":"May 28, 2019","tags":[{"label":"hola","permalink":"/docion/blog/tags/hola"},{"label":"docusaurus","permalink":"/docion/blog/tags/docusaurus"}],"readingTime":0.12,"hasTruncateMarker":false,"authors":[{"name":"Gao Wei","title":"Docusaurus Core Team","url":"https://github.com/wgao19","image_url":"https://github.com/wgao19.png","imageURL":"https://github.com/wgao19.png"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":{"name":"Gao Wei","title":"Docusaurus Core Team","url":"https://github.com/wgao19","image_url":"https://github.com/wgao19.png","imageURL":"https://github.com/wgao19.png"},"tags":["hola","docusaurus"],"hide_table_of_contents":false},"prevItem":{"title":"Long Blog Post","permalink":"/docion/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}]}')}}]);